{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add libraries \n",
    "import csv \n",
    "import os\n",
    "import glob\n",
    "import re \n",
    "from pandas import read_csv\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all_input_datasets=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\input\\2019_*.csv'\n",
    "path_to_combine_dir=r\"C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\data prep\"\n",
    "path_Combined_dataset=r\"C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\Combined\\2019_TL1.csv\"\n",
    "path_resultant_dataprep=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\Combined\\2019_TL1.csv'\n",
    "path_filtered_dataset=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\Filtered\\Filtered.csv'\n",
    "path_output_dataset=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\Output\\Final(Direct).csv'\n",
    "path_sd_OP=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\sd\\Combine\\SD.csv'\n",
    "path_sd_IP=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\sd\\split'\n",
    "FinalPath=r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\OUTPUT(FINAL_DIRECT)\\DirectLayer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign and drop headers and columns \n",
    "def Data_preparation(path):\n",
    "    count=0\n",
    "    for filename in glob.glob(path):\n",
    "        Temp_df= pd.read_csv(filename)   \n",
    "        Temp_df.drop(Temp_df.columns[len(Temp_df.columns)-1], axis=1, inplace=True)  \n",
    "        Temp_df.drop(Temp_df.columns[len(Temp_df.columns)-1], axis=1, inplace=True)\n",
    "        Temp_df.drop(Temp_df.columns[len(Temp_df.columns)-1], axis=1, inplace=True)\n",
    "        Temp_df.columns = ['year','month (in digit)','DAY','DayType','Bin (min)','Shift (min)','Time (hr)','SampleSize','MeanTT(sec)','Median','Mode','Max','Min','Variance','StandardDev of TT (v2v)','LowerQUartile','UpperQuartile','95th_Percentile of TT','Buffer time','BufferTimeIndex'] # Assign headers to the dataset\n",
    "        cols = ['year','month (in digit)','DAY']   \n",
    "        newcol = ['-'.join(i) for i in Temp_df[cols].astype(str).values]\n",
    "        Temp_df = Temp_df.assign(Date=newcol).drop(cols, 1)\n",
    "        Temp_df[\"Date\"]= pd.to_datetime(Temp_df[\"Date\"])\n",
    "        Temp_df[\"Day_of_week\"]=Temp_df[\"Date\"].dt.dayofweek\n",
    "        Temp_df[\"Day_name\"]=Temp_df[\"Date\"].dt.day_name()\n",
    "        Temp_df.to_csv(r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\data preparation\\data prep\\C%s.csv' %count,index=False) # Save the modelled data for combination\n",
    "        count=count+1 \n",
    "\n",
    "#combine the prepared data into a single file         \n",
    "def Data_combination(ipath,opath):\n",
    "    os.chdir(ipath)\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    combined_csv.to_csv(opath, index=False, encoding='utf-8-sig') \n",
    "    return combined_csv\n",
    "\n",
    "#filter the day any time for the dataset \n",
    "def Data_filtering(ipath,opath):\n",
    "    tl_df_de= pd.read_csv(ipath)\n",
    "    Day_filter_de = tl_df_de[tl_df_de['DayType']==1]\n",
    "    Time_filter1_de = Day_filter_de[Day_filter_de['Time (hr)']>=7]\n",
    "    Time_filter2_de = Time_filter1_de[Time_filter1_de['Time (hr)']<=9]\n",
    "    Time_filter2_de=Time_filter2_de.reset_index(drop=True)\n",
    "    Time_filter2_de.to_csv(opath, index=False, encoding='utf-8-sig') \n",
    "    return Time_filter2_de\n",
    "\n",
    "def sd(Filtered_df):\n",
    "    Dow=Filtered_df['Day_of_week'].unique()\n",
    "    Dow=list(Dow)\n",
    "    Toh=Filtered_df['Time (hr)'].unique()\n",
    "    Toh=list(Toh)\n",
    "    count=0\n",
    "    for x in Dow: \n",
    "        for y in Toh:\n",
    "            df_8am=Filtered_df.loc[Filtered_df['Day_of_week']==x]\n",
    "            df_8am=df_8am.loc[df_8am['Time (hr)']==y]\n",
    "            df_8am=df_8am.reset_index(drop=True)\n",
    "            df_8am['sample_Mean']=\" \"\n",
    "            for i in range(len(df_8am)):\n",
    "                df_8am.loc[i,'sample_Mean']=df_8am.loc[i,'MeanTT(sec)']*df_8am.loc[i,'SampleSize']\n",
    "                        #x^=sum(x*n)/sum(n)\n",
    "            df_8am['x']=df_8am['sample_Mean'].sum()/df_8am['SampleSize'].sum()    \n",
    "            df_8am['d']=\" \"\n",
    "            for i in range(len(df_8am)):\n",
    "                df_8am.loc[i,'d']=df_8am.loc[i,'MeanTT(sec)']-df_8am.at[i,'x']         \n",
    "            df_8am['variance_']=\" \"\n",
    "            for i in range(len(df_8am)):\n",
    "                df_8am.loc[i,'variance_']=df_8am.loc[i,'SampleSize']*(df_8am.loc[i,'Variance']+df_8am.loc[i,'d']**2)\n",
    "\n",
    "            df_8am['S.D_at_Time']=np.sqrt(df_8am['variance_'].sum()/df_8am['SampleSize'].sum())\n",
    "            df_8am.to_csv(r'C:\\Users\\shesa\\Dropbox\\Saagar\\Sara\\Code\\Modified Code\\Direct layer\\sd\\split\\C%s.csv' %count,index=False)\n",
    "            count=count+1\n",
    "#Set a lower and upper bound for the mean travel time\n",
    "def Time_bound(df):\n",
    "    for i in range(len(df)):\n",
    "        if (df.at[i,'MeanTT(sec)']<25):\n",
    "            df.at[i,'MeanTT(sec)']=0\n",
    "            df.at[i,'SampleSize']=0      \n",
    "    for i in range(len(df)):\n",
    "        if (df.at[i,'MeanTT(sec)']>300):\n",
    "            df.at[i,'MeanTT(sec)']=0\n",
    "            df.at[i,'SampleSize']=0\n",
    "    \n",
    "    return df \n",
    "\n",
    "#Calculate the standard error and weight for the dataset \n",
    "def Standard_error_and_weight(df,opath):\n",
    "    df['StandardDEv(min)']=\" \" #Converting the SD into Minutes \n",
    "    for i in range(len(df)):\n",
    "        df.at[i,'StandardDEv(min)']=(df.at[i,'S.D_at_Time']/60)\n",
    "\n",
    "    df['standard error']=\" \" #Standard Error \n",
    "    for i in range(len(df)):\n",
    "        df.at[i,'standard error']=df.at[i,'StandardDEv(min)']/np.sqrt((df.at[i,'SampleSize']))\n",
    "\n",
    "    df['Weight']='' #Weight for Backward Layer     \n",
    "    alpha=2.54\n",
    "    e=2.71828\n",
    "    for i in range(len(df)):\n",
    "        df.at[i,'Weight']=alpha*(e**(-alpha*df.at[i,'standard error']))\n",
    "    \n",
    "    df.to_csv(opath, index=False, encoding='utf-8-sig')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shesa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' : \n",
    "    Data_preparation(path_all_input_datasets)\n",
    "    dfc=Data_combination(path_to_combine_dir,path_Combined_dataset)\n",
    "    Filtered_df=Data_filtering(path_resultant_dataprep,path_filtered_dataset)\n",
    "    sd(Filtered_df)\n",
    "    combined_sd=Data_combination(path_sd_IP,path_sd_OP)\n",
    "    combined_sd=combined_sd.reset_index(drop=True)\n",
    "    Bound_df=Time_bound(combined_sd)\n",
    "#     Bound_df.drop(Bound_df.loc[Bound_df['SampleSize']==0].index,inplace=True)\n",
    "#     Bound_df=Bound_df.reset_index(drop=True)\n",
    "    OP=Standard_error_and_weight(Bound_df,path_output_dataset)\n",
    "    OP=OP.sort_values(['Date', 'Time (hr)'], ascending=[True, True])\n",
    "    OP=OP.reset_index(drop=True)\n",
    "    OP.to_csv(FinalPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5929 entries, 0 to 5928\n",
      "Data columns (total 28 columns):\n",
      "DayType                    5929 non-null int64\n",
      "Bin (min)                  5929 non-null int64\n",
      "Shift (min)                5929 non-null int64\n",
      "Time (hr)                  5929 non-null float64\n",
      "SampleSize                 5929 non-null int64\n",
      "MeanTT(sec)                5311 non-null float64\n",
      "Median                     5311 non-null float64\n",
      "Mode                       5311 non-null float64\n",
      "Max                        5311 non-null float64\n",
      "Min                        5311 non-null float64\n",
      "Variance                   5311 non-null float64\n",
      "StandardDev of TT (v2v)    5311 non-null float64\n",
      "LowerQUartile              5311 non-null float64\n",
      "UpperQuartile              5311 non-null float64\n",
      "95th_Percentile of TT      5311 non-null float64\n",
      "Buffer time                5311 non-null float64\n",
      "BufferTimeIndex            5311 non-null float64\n",
      "Date                       5929 non-null object\n",
      "Day_of_week                5929 non-null int64\n",
      "Day_name                   5929 non-null object\n",
      "sample_Mean                5311 non-null float64\n",
      "x                          5929 non-null float64\n",
      "d                          5311 non-null float64\n",
      "variance_                  5311 non-null float64\n",
      "S.D_at_Time                5929 non-null float64\n",
      "StandardDEv(min)           5929 non-null object\n",
      "standard error             5929 non-null object\n",
      "Weight                     5929 non-null object\n",
      "dtypes: float64(18), int64(5), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "OP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
